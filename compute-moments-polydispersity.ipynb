{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import scipy.stats\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import intake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = intake.open_catalog('data/MicroCTData/catalog.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = db.chords.read()\n",
    "ice_vol = db.ice_vol_frac.read()\n",
    "\n",
    "metadata = db.information.read()\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moment(cdl, order, material):\n",
    "    return np.sum(cdl['i'] ** order * cdl['l_' + material]) / np.sum(cdl['l_' + material])\n",
    "\n",
    "def moment_total(cdl, order):\n",
    "    l_ice = cdl['l_ice'] / np.sum(cdl['l_ice'])\n",
    "    l_pore = cdl['l_pore'] / np.sum(cdl['l_pore'])\n",
    "\n",
    "    c_i_p = np.convolve(l_ice, l_pore)[0:len(l_ice)]\n",
    "\n",
    "    g = l_ice + l_pore - 2 * c_i_p[0:len(l_ice)] + np.convolve(l_ice, c_i_p)[0:len(l_ice)] + np.convolve(l_pore, c_i_p)[0:len(l_ice)]\n",
    "    return np.sum(cdl['i'] ** order * g) / np.sum(g)\n",
    "\n",
    "\n",
    "stats = {f'{m}_mu{o}': df.groupby('site').apply(moment, order=o, material=m) \\\n",
    "                      for o in [0, 1, 2, 3, 4] for m in ['ice', 'pore']}\n",
    "\n",
    "stats.update({f'mu{o}': df.groupby('site').apply(moment_total, order=o) \\\n",
    "                      for o in [0, 1, 2, 3, 4]})\n",
    "\n",
    "stats = pd.DataFrame(stats).join(ice_vol.set_index('site'))\n",
    "\n",
    "stats = stats.join(metadata.set_index('filename'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impact of the different order in phi\n",
    "\n",
    "Klp = (stats.ice_mu4 / (24*stats.ice_mu1**4))**(1/3)\n",
    "\n",
    "phi_1 = 1 - stats.ice_vol_frac\n",
    "Klp_semidilue = ((stats.ice_mu4/(24*stats.ice_mu1**4) - \\\n",
    "                 stats.ice_mu2*stats.ice_mu3/(6*stats.ice_mu1**5) * (1-phi_1) \\\n",
    "                 + stats.ice_mu2**3/(8*stats.ice_mu1**6) * (1-phi_1)**2 ) / phi_1**2) ** (1/3)\n",
    "\n",
    "#phi_1 = 0.5\n",
    "Klp_semidilue_terms = pd.DataFrame({\n",
    "    'phi': stats.ice_vol_frac,\n",
    "    't1': stats.ice_mu4/(24*stats.ice_mu1**4),\n",
    "    't2': - stats.ice_mu2*stats.ice_mu3/(6*stats.ice_mu1**5) * (1-phi_1),\n",
    "    't3':  stats.ice_mu2**3/(8*stats.ice_mu1**6)* (1-phi_1)**2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowtypes = [['RG'], ['FC'], ['MF'], ['RG', 'FC', 'MF'], ['DH']]\n",
    "\n",
    "for snowtype in snowtypes:\n",
    "    mask = stats.main_type.isin(snowtype)\n",
    "    print(\"----\", snowtype)\n",
    "    print(\"n=\", mask.sum())\n",
    "    n = mask.sum()\n",
    "    mean = Klp_semidilue[mask].mean()\n",
    "    std = Klp_semidilue[mask].std()\n",
    "    print(f\"{mean:.2} +- {std:.2} (n={n})\")\n",
    "    print(Klp_semidilue[mask].min(), Klp_semidilue[mask].max())\n",
    "    \n",
    "for snowtype1, snowtype2 in itertools.product(snowtypes, snowtypes):\n",
    "    if snowtype1 is snowtype2:\n",
    "        continue\n",
    "\n",
    "    mask1 = stats.main_type.isin(snowtype1)\n",
    "    mask2 = stats.main_type.isin(snowtype2)\n",
    "    \n",
    "    t = scipy.stats.ttest_ind(Klp_semidilue[mask1], Klp_semidilue[mask2], equal_var = False)\n",
    "\n",
    "    print(snowtype1, snowtype2, \"p=\", t.pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats['K'] = Klp_semidilue  #[normalsnow].sort_values().to_csv('output-polydispersity.csv')\n",
    "stats.to_csv('results/polydispersity-all-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalsnow = stats.main_type.isin(['RG', 'FC', 'MF'])\n",
    "DHsnow = stats.main_type.isin(['DH'])\n",
    "\n",
    "blue = \"#1f77b4\"\n",
    "orange = \"#ff7f0e\"\n",
    "\n",
    "f, axs = plt.subplots(1, 1, figsize=(8.7, 3.4), sharey=True)\n",
    "\n",
    "Kl_special = {'Antarctic snow\\n(from\\nmicrowaves)': (0.63, '--'),\n",
    "              #'Arctic Depth Hoar\\n(from microwaves)': (1.48, '-'),\n",
    "              'Sparse\\nspheres\\n(from theory)': ((9/128)**(1/3), ':'),\n",
    "              'Debye random medium\\n(from theory)': (1, ':'),\n",
    "             }\n",
    "for label, (K, s) in Kl_special.items():\n",
    "    #axs.plot([K, K],[0, 24], s, label=label)\n",
    "    line = 0 if 'Depth Hoar' in label else 1.05\n",
    "    \n",
    "    axs.arrow(K, 0, 0, 35, edgecolor=blue, linestyle=s, linewidth=2)\n",
    "    axs.annotate(label, xy=[K, line], \n",
    "                 xycoords=('data', 'axes fraction'),\n",
    "                 horizontalalignment='center'\n",
    "                )\n",
    "        \n",
    "axs.arrow(0.8, -20, 0.4, 0, edgecolor=orange, linewidth=2)\n",
    "axs.annotate(\"Finnish depth hoar\\n(from $\\mu$-CT, Leinss et al. 2020)\", xy=(1, -20-8), horizontalalignment='center')\n",
    "\n",
    "axs.arrow(1.2, -15, 0.7, 0, edgecolor=orange, linestyle='--', linewidth=2)\n",
    "axs.annotate(\"Canadian arctic depth hoar\\n(from microwaves)\", xy=(1.5, -17-7), horizontalalignment='center')\n",
    "\n",
    "bins = np.arange(0.4, 1.5, 0.04)\n",
    "#axs[0].hist(Kl[normalsnow], alpha=0.3, bins=bins, label='Rounded and faceted grains (from $\\mu$CT)')\n",
    "#axs[0].hist(Kl[DHsnow], alpha=0.3, bins=bins, label='Alpine Depth hoar (from $\\mu$CT)')\n",
    "\n",
    "axs.hist(Klp_semidilue[normalsnow], alpha=0.5, bins=bins, edgecolor='0.5', label='Alpine convex grains\\n(from CLD)')\n",
    "#axs.hist(Klp_semidilue[DHsnow], hatch='//\\\\\\\\', edgecolor='0.6', alpha=0.3, bins=bins, histtype='step', label='Alpine Depth Hoar (from chord length distribution)')\n",
    "h, e = np.histogram(Klp_semidilue[DHsnow], bins=bins)\n",
    "axs.bar(e[:-1], -h, width=np.diff(e), \n",
    "        align='edge', edgecolor='0.6', facecolor='#ff7f0e', alpha=0.3, label='Alpine Depth Hoar\\n(from CLD)')\n",
    "\n",
    "\n",
    "#axs.set_frame(False)\n",
    "axs.set_ylim((-30, 30))\n",
    "axs.set_xlabel(\"Polydispersity $K$\", loc='right', labelpad=-33)\n",
    "axs.set_ylabel(\"Number of samples\")\n",
    "#axs.yaxis.visible = True\n",
    "axs.spines['bottom'].set_position('zero')\n",
    "\n",
    "axs.spines['left'].set_visible(True)\n",
    "axs.spines['top'].set_visible(False)\n",
    "axs.spines['right'].set_visible(False)\n",
    "#axs.yaxis.set_tick_params(left='off', right='off', length=0, labelsize=0)\n",
    "axs.yaxis.set_tick_params(right='off')\n",
    "axs.yaxis.set_major_formatter(lambda x, pos: int(abs(x)))\n",
    "\n",
    "axs.legend(framealpha=0.3, prop={'size': 8}, loc='lower left')\n",
    "f.tight_layout()\n",
    "f.savefig(\"fig-polydispersity.pdf\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "satpy",
   "language": "python",
   "name": "satpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
